unet:
  dim: 64
  dim_mults: [1, 2, 4, 8]
  self_condition: True

diffusion:
  image_size: [320, 240]
  timesteps: 1000
  sampling_timesteps: 250
  loss_type: "l2"
  beta_schedule: "linear"

trainer:
  folder: Null
  results_folder: Null
  train_batch_size: 16
  gradient_accumulate_every: 4
  split_batches: True
  train_lr: 2.e-5
  train_num_steps: 10000000
  augment_horizontal_flip: False
  ema_decay: 0.9999            
  amp: False
  save_and_sample_every: 5000
